# -*- coding: utf-8 -*-
"""mainfyp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kRRcK9CpBgKMV3gZeMIHsmurkNR4QPSV
"""

import streamlit as st
import numpy as np
import tensorflow as tf
from PIL import Image
import io
import requests
import json
import os
import tempfile
!pip install librosa

# Set page configuration
st.set_page_config(
    page_title="Speech Emotion Recognition",
    page_icon="üé≠",
    layout="centered"
)

# Check if model exists and load it
@st.cache_resource
def load_model():
    model_path = "./res_model.keras"
    if os.path.exists(model_path):
        print(f"Loading model from {model_path}")
        return tf.keras.models.load_model(model_path)
    else:
        st.error(f"Model file not found at {model_path}. Please run fyp_test.py first.")
        return None

def get_features(path, duration=2.5, offset=0.6):
    # Example feature extraction: MFCC stats (replace with your actual function)
    data, sr = librosa.load(path, duration=duration, offset=offset)
    target_length = int(sr * duration)
    if len(data) < target_length:
        data = np.pad(data, (0, target_length - len(data)))
    elif len(data) > target_length:
        data = data[:target_length]

    mfcc_feat = librosa.feature.mfcc(y=data, sr=sr, n_mfcc=13)
    result = []
    for i in range(mfcc_feat.shape[0]):
        result.extend([
            np.mean(mfcc_feat[i]),
            np.std(mfcc_feat[i]),
            np.min(mfcc_feat[i]),
            np.max(mfcc_feat[i])
        ])
    return np.array(result)  # Should return fixed length vector (e.g., length 52)

def process_features(features, model):
    # Reshape features to (1, timesteps=52, features=1) for Conv1D input
    if len(features.shape) == 1:
        features = features.reshape(1, -1, 1)
    elif len(features.shape) == 2:
        features = np.expand_dims(features, axis=-1)

    with st.spinner('Analyzing emotion...'):
        predictions = model.predict(features, verbose=0)
        emotion_index = np.argmax(predictions[0])

        emotion_labels = ['neutral', 'surprise', 'happy', 'fear', 'sad', 'angry', 'disgust']
        emotion = emotion_labels[emotion_index]
        confidence = float(predictions[0][emotion_index])

    col1, col2 = st.columns(2)

    with col1:
        st.subheader("Detected Emotion")

        emotion_colors = {
            'happy': '#FFD700',
            'sad': '#4169E1',
            'angry': '#DC143C',
            'neutral': '#808080',
            'fear': '#9932CC',
            'disgust': '#228B22',
            'surprise': '#FF8C00'
        }

        st.markdown(
            f"""
            <div style="background-color: {emotion_colors.get(emotion, '#808080')};
                      padding: 20px;
                      border-radius: 10px;
                      text-align: center;
                      color: white;
                      font-size: 24px;
                      font-weight: bold;">
                {emotion.upper()}
            </div>
            """,
            unsafe_allow_html=True
        )

        st.subheader("Confidence")
        st.progress(confidence)
        st.text(f"{confidence:.2%}")

        st.subheader("All Probabilities")
        for i, label in enumerate(emotion_labels):
            st.text(f"{label.capitalize()}: {predictions[0][i]:.4f}")

    with col2:
        st.subheader("Emoticon")
        emoticon_data = generate_emoticon(emotion)
        if emoticon_data:
            image = Image.open(io.BytesIO(emoticon_data))
            st.image(image, caption=f"{emotion.capitalize()} Emoticon", use_column_width=True)
        else:
            emotion_emojis = {
                'happy': "üòä", 'sad': "üò¢", 'angry': "üò†",
                'neutral': "üòê", 'fear': "üò®", 'disgust': "ü§¢", 'surprise': "üò≤"
            }
            st.markdown(f"<h1 style='text-align: center; font-size: 100px;'>{emotion_emojis.get(emotion, '‚ùì')}</h1>", unsafe_allow_html=True)

def main():
    st.title("üé≠ Speech Emotion Recognition")
    st.write("Upload a WAV audio file to detect emotion")

    # Sidebar unchanged...

    model = load_model()
    if model is None:
        st.warning("Please run fyp_test.py to create the model before using this app.")
        return

    # Accept WAV files only, no demo mode
    uploaded_file = st.file_uploader("Upload your audio file", type=["wav"])

    if uploaded_file is not None:
        st.audio(uploaded_file, format='audio/wav')

        # Save uploaded WAV to temp file for librosa to read
        with tempfile.NamedTemporaryFile(suffix=".wav") as temp_wav:
            temp_wav.write(uploaded_file.read())
            temp_wav.flush()

            features = get_features(temp_wav.name)  # Extract features
            process_features(features, model)

if __name__ == "__main__":
    main()
