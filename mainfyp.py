# -*- coding: utf-8 -*-
"""mainfyp.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kRRcK9CpBgKMV3gZeMIHsmurkNR4QPSV
"""

!pip install streamlit
import streamlit as st
import numpy as np
import tensorflow as tf
from PIL import Image
import io
import requests
import json
import os

# Set page configuration
st.set_page_config(
    page_title="Speech Emotion Recognition",
    page_icon="üé≠",
    layout="centered"
)

# Check if model exists and load it
@st.cache_resource
def load_model():
    model_path = "./res_model.keras"
    if os.path.exists(model_path):
        print(f"Loading model from {model_path}")
        return tf.keras.models.load_model(model_path)
    else:
        st.error(f"Model file not found at {model_path}. Please run fyp_test.py first.")
        return None

# Function to generate emoticon using OpenAI API
def generate_emoticon(emotion):
    try:
        # OpenAI API endpoint for DALL-E
        api_url = "https://api.openai.com/v1/images/generations"

        # Replace with your actual API key (better to use environment variables or st.secrets)
        # api_key = "YOUR_API_KEY_HERE"
        api_key = st.secrets.get("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", "")

        if not api_key:
            st.warning("OpenAI API key not configured. Using emoji fallback.")
            return None

        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

        # Customize the prompt based on emotion
        prompt_mapping = {
            'happy': "a simple happy emoticon with a big smile",
            'sad': "a simple sad emoticon with a frown and tear",
            'angry': "a simple angry emoticon with furrowed brows",
            'neutral': "a simple neutral emoticon with straight face",
            'fear': "a simple scared emoticon with wide eyes",
            'disgust': "a simple disgusted emoticon with wrinkled nose",
            'surprise': "a simple surprised emoticon with open mouth"
        }

        prompt = prompt_mapping.get(emotion, "a simple emoticon")

        payload = {
            "prompt": prompt,
            "n": 1,
            "size": "256x256"
        }

        with st.spinner('Generating emoticon...'):
            response = requests.post(api_url, headers=headers, data=json.dumps(payload))
            response_data = response.json()

            if 'error' in response_data:
                st.error(f"API Error: {response_data['error']['message']}")
                return None

            # Extract the image URL from the response
            image_url = response_data['data'][0]['url']

            # Download the image
            image_response = requests.get(image_url)
            if image_response.status_code == 200:
                return image_response.content
            else:
                st.error(f"Failed to download image: {image_response.status_code}")
                return None

    except Exception as e:
        st.error(f"Error generating emoticon: {e}")
        return None

def main():
    st.title("üé≠ Speech Emotion Recognition")
    st.write("Upload an audio feature file (.npy) to detect emotion")

    # Sidebar with information
    with st.sidebar:
        st.header("About")
        st.info("""
        This app recognizes emotions from speech using a neural network.

        Supported emotions:
        - Happy
        - Sad
        - Angry
        - Neutral
        - Fear
        - Disgust
        - Surprise
        """)

        st.header("Instructions")
        st.write("""
        1. First, run the train_model.py script to create the model
        2. Then run this Streamlit app
        3. Upload a .npy file containing audio features
        4. The app will predict the emotion
        """)

    # Load the model
    model = load_model()

    # Only proceed if model is loaded
    if model is None:
        st.warning("Please run train_model.py to create the model before using this app.")
        return

    # File uploader
    uploaded_file = st.file_uploader("Upload audio feature file (.npy)", type=["npy"])

    # Demo mode checkbox
    demo_mode = st.checkbox("Use demo mode with random features")

    # Process the file or generate demo data
    if uploaded_file is not None or demo_mode:
        try:
            if demo_mode:
                # Generate random features for demo
                st.info("Using randomly generated features for demonstration")
                features = np.random.rand(128)  # Create random features
            else:
                # Load features from the uploaded file
                features = np.load(uploaded_file)

            # Process features for prediction
            # Ensure the features have the right shape for the model
            if len(features.shape) == 1:
                # Reshape for single sample: (1, n_features, 1)
                features = np.expand_dims(features, axis=0)
                features = np.expand_dims(features, axis=-1)

            # Predict emotion
            with st.spinner('Analyzing emotion...'):
                predictions = model.predict(features, verbose=0)
                emotion_index = np.argmax(predictions[0])

                # Map index to emotion label
                emotion_labels = ['neutral', 'surprise', 'happy', 'fear', 'sad', 'angry', 'disgust']
                emotion = emotion_labels[emotion_index]
                confidence = float(predictions[0][emotion_index])

            # Create columns for displaying results
            col1, col2 = st.columns(2)

            # Display results in the first column
            with col1:
                st.subheader("Detected Emotion")

                # Color-coded box for the emotion
                emotion_colors = {
                    'happy': '#FFD700',  # Gold
                    'sad': '#4169E1',    # Royal Blue
                    'angry': '#DC143C',  # Crimson
                    'neutral': '#808080', # Gray
                    'fear': '#9932CC',   # Dark Orchid
                    'disgust': '#228B22', # Forest Green
                    'surprise': '#FF8C00' # Dark Orange
                }

                # Display the emotion in a colored box
                st.markdown(
                    f"""
                    <div style="background-color: {emotion_colors.get(emotion, '#808080')};
                              padding: 20px;
                              border-radius: 10px;
                              text-align: center;
                              color: white;
                              font-size: 24px;
                              font-weight: bold;">
                        {emotion.upper()}
                    </div>
                    """,
                    unsafe_allow_html=True
                )

                # Display confidence as a progress bar
                st.subheader("Confidence")
                st.progress(confidence)
                st.text(f"{confidence:.2%}")

                # Display all emotion probabilities
                st.subheader("All Probabilities")
                for i, label in enumerate(emotion_labels):
                    st.text(f"{label.capitalize()}: {predictions[0][i]:.4f}")

            # Generate and display emoticon in the second column
            with col2:
                st.subheader("Emoticon")

                # Try to generate emoticon using OpenAI API
                emoticon_data = generate_emoticon(emotion)
                if emoticon_data:
                    image = Image.open(io.BytesIO(emoticon_data))
                    st.image(image, caption=f"{emotion.capitalize()} Emoticon", use_column_width=True)
                else:
                    # Fallback to emoji if image generation fails
                    emotion_emojis = {
                        'happy': "üòä", 'sad': "üò¢", 'angry': "üò†",
                        'neutral': "üòê", 'fear': "üò®", 'disgust': "ü§¢", 'surprise': "üò≤"
                    }
                    st.markdown(f"<h1 style='text-align: center; font-size: 100px;'>{emotion_emojis.get(emotion, '‚ùì')}</h1>", unsafe_allow_html=True)

        except Exception as e:
            st.error(f"Error processing audio features: {e}")
            st.error("Please ensure you're uploading a valid NumPy (.npy) file with audio features")

if __name__ == "__main__":
    main()